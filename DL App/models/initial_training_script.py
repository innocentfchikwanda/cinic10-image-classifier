# -*- coding: utf-8 -*-
"""Deep Learning PROSIT One

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16X0WNRkeRrtZA3fEPdgPTzeK2y0fxT2N
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files, drive

import torch
import torchvision.transforms as transforms

from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset

import torch.nn as nn
import torch.nn.functional as F

drive.mount('/content/drive')

"""# Getting the Dataset

## Downloading and moving to the cloud
"""

# files.upload() # kaggle api token

# !mkdir -p ~/.kaggle
# !cp kaggle.json ~/.kaggle/
# !chmod 600 ~/.kaggle/kaggle.json

# !mkdir -p /content/drive/MyDrive/KaggleData/CINIC10

# !kaggle datasets download -d mengcius/cinic10 -p /content/drive/MyDrive/KaggleData/CINIC10

# !unzip /content/drive/MyDrive/KaggleData/CINIC10/cinic10.zip -d /content/drive/MyDrive/KaggleData/CINIC10

"""## Verifying data upload"""

dataset = '/content/drive/MyDrive/KaggleData/CINIC10'

def count_files_and_folders(path):
    total_files = 0
    total_folders = 0
    print(f"{path}/")
    for root, dirs, files in os.walk(path):
        level = root.replace(path, '').count(os.sep)

        indent = ' ' * 4 * (level)
        print(f'{indent}|-- {os.path.basename(root)}/')

        subindent = ' ' * 4 * (level + 1)
        print(f'{subindent}|-- Folders: {len(dirs)}')
        print(f'{subindent}|-- Files: {len(files)}')
        total_files += len(files)
        total_folders += len(dirs)
    print(f"\nTotal Folders: {total_folders}")
    print(f"Total Files: {total_files}")

count_files_and_folders(dataset)

"""# Data Preprocessing

## Transforms for normaization
"""

transform = transforms.Compose([
    transforms.Resize((32, 32)),          # Ensure all images are 32x32
    transforms.ToTensor(),                # Convert to tensor [0,1]
    transforms.Normalize(
        mean=[0.4789, 0.4723, 0.4305],    # Training set stats
        std=[0.2421, 0.2383, 0.2587]
    ),
    transforms.Lambda(lambda x: x.view(-1))  # Flatten (3,32,32) -> (3072,)
])

"""## Loading the data"""

train_data = ImageFolder("/content/drive/MyDrive/KaggleData/CINIC10/train",
                         transform=transform)
val_data   = ImageFolder("/content/drive/MyDrive/KaggleData/CINIC10/valid",
                         transform=transform)
test_data  = ImageFolder("/content/drive/MyDrive/KaggleData/CINIC10/test",
                         transform=transform)

"""### Didn't use"""

# @title
full_dataset = ConcatDataset([train_data, val_data, test_data])
full_size = len(full_dataset)
print("Full size:", full_size)

# subsetting 10%
subset_size = int(0.10 * full_size)
remaining = full_size - subset_size

torch.manual_seed(42)

small_subset, _ = random_split(full_dataset, [subset_size, remaining])
print("Small subset size:", len(small_subset))

# splitting 10% subset into 75/15/10 for train val and test
train_size = int(0.75 * subset_size)
val_size   = int(0.15 * subset_size)
test_size  = subset_size - train_size - val_size

train_subset, val_subset, test_subset = random_split(
    small_subset, [train_size, val_size, test_size]
)

print(len(train_subset), len(val_subset), len(test_subset))

"""### Sampling from each"""

train_size = int(0.1 * len(train_data))
val_size   = int(0.1 * len(val_data))
test_size  = int(0.1 * len(test_data))

# sample indices for each
train_indices = torch.randperm(len(train_data))[:train_size]
val_indices   = torch.randperm(len(val_data))[:val_size]
test_indices  = torch.randperm(len(test_data))[:test_size]

# subset datasets
train_small = Subset(train_data, train_indices)
val_small   = Subset(val_data, val_indices)
test_small  = Subset(test_data, test_indices)

print("Full dataset sizes:")
print("Train:", len(train_data))
print("Valid:", len(val_data))
print("Test:", len(test_data))

print("\nSampled dataset sizes")
print("Train small:", len(train_small))
print("Valid small:", len(val_small))
print("Test small:", len(test_small))

"""### Setting dataloaders for each set"""

train_loader = DataLoader(train_small, batch_size=128, shuffle=True, num_workers=2)
val_loader   = DataLoader(val_small, batch_size=128, shuffle=False, num_workers=2)
test_loader  = DataLoader(test_small, batch_size=128, shuffle=False, num_workers=2)

"""### View sample images"""

def imshow(img, mean=[0.4789, 0.4723, 0.4305], std=[0.2421, 0.2383, 0.2587]):
    img = img.numpy().transpose((1, 2, 0))   # CxHxW -> HxWxC
    img = std * img + mean                   # Unnormalize
    img = np.clip(img, 0, 1)                 # clamp between [0,1]
    plt.imshow(img)
    plt.axis("off")

# take a batch from train loader
dataiter = iter(train_loader)
images, labels = next(dataiter)

# show first 5 images
plt.figure(figsize=(6, 2))
for i in range(5): # Changed range from 10 to 5
    plt.subplot(1, 5, i+1)
    imshow(images[i].view(3, 32, 32))  # reshape back since DFN flattens
    plt.title(labels[i].item())
plt.show()

# Plot after each epoch
def plot_losses(train_losses):
  plt.figure(figsize=(8,4))
  plt.plot(train_losses, label='Training Loss')
  plt.xlabel('Iteration (every 10 batches)')
  plt.ylabel('Loss')
  plt.title('Training Loss Progress')
  plt.legend()
  plt.show()

"""# Deep feed forward network

## Training
"""

def train(model, num_epochs=10):
    train_losses = []

    for epoch in range(num_epochs):
      model.train()
      running_loss = 0.0

      for i, (images, labels) in enumerate(train_loader, 1):
          # clear gradients
          optimizer.zero_grad()

          # get outputs
          outputs = model.forward_net(images)

          # calculate loss and do backprop
          loss = criterion(outputs, labels)
          loss.backward()

          # update weights
          optimizer.step()

          running_loss += loss.item()

          if i % 10 == 0:
            avg_loss = running_loss / 10
            print(f"Epoch [{epoch+1}/{num_epochs}], Batch [{i}/{len(train_loader)}], Loss: {avg_loss:.4f}")
            train_losses.append(avg_loss)
            running_loss = 0.0

      # Validation
      model.eval()
      correct, total = 0, 0

      with torch.no_grad():
        for images, labels in val_loader:
          outputs = model.forward_net(images)
          _, predicted = torch.max(outputs, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()
      print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}, Val Acc: {100*correct/total:.2f}%")

# bare bones
class FeedforwardNet(nn.Module):
    def __init__(self):
        super(FeedforwardNet, self).__init__()
        self.fc1 = nn.Linear(3072, 1024)   # first hidden layer
        self.fc2 = nn.Linear(1024, 512)    # second hidden layer
        self.fc3 = nn.Linear(512, 256)     # third hidden layer
        self.fc4 = nn.Linear(256, 10)      # output layer

    def forward_net(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = self.fc4(x)   # logits
        return x

barebones_model = FeedforwardNet()

criterion = nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(barebones_model.parameters(), lr=0.01)

train(barebones_model, num_epochs=10)

"""## Test"""

def test(model):
  model.eval()
  correct, total = 0, 0
  with torch.no_grad():
      for images, labels in test_loader:
          outputs = model.forward_net(images)
          _, predicted = torch.max(outputs, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()

  print(f"Test Accuracy: {100*correct/total:.2f}%")

test(barebones_model)


